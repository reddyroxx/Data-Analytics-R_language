{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 a)\n",
    "\n",
    "#in train.csv\n",
    "\n",
    "train_means = df_train.groupby(['user_id'])['rating'].mean()\n",
    "#print(train_means)\n",
    "\n",
    "#in test.csv\n",
    "test_means = df_test.groupby(['user_id'])['rating'].mean()\n",
    "#print(test_means)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 b)\n",
    "\n",
    "#in train.csv\n",
    "train_item_means = df_train.groupby(['book'])['rating'].mean()\n",
    "#print(train_item_means)\n",
    "\n",
    "#in test.csv\n",
    "test_item_means = df_test.groupby(['book'])['rating'].mean()\n",
    "#print(test_item_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 c)\n",
    "\n",
    "train_avgs = list(df_train['rating'])\n",
    "test_avgs = list(df_test['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean square error for train.csv =  1.781336407021028\n",
      "Root mean square error for test.csv =  1.8370063986986185\n"
     ]
    }
   ],
   "source": [
    "#1 c)\n",
    "def rmse(arr1,arr2):\n",
    "    return math.sqrt(mean_squared_error(arr1, arr2))\n",
    "\n",
    "df_train_avg = df_train['rating'].mean()\n",
    "df_test_avg = df_test['rating'].mean()\n",
    "\n",
    "#print(\"Average value for ratings in train.csv = \",df_train_avg)\n",
    "#print(\"Average value for ratings in test.csv = \",df_test_avg)\n",
    "\n",
    "[df_train_avg]*len(df_train['rating'])\n",
    "const_avg_train = [df_train_avg]*len(df_train['rating'])\n",
    "\n",
    "[df_test_avg]*len(df_test['rating'])\n",
    "const_avg_test = [df_test_avg]*len(df_test['rating'])\n",
    "\n",
    "#in train.csv\n",
    "rmse_train = rmse(train_avgs,const_avg_train)\n",
    "print(\"Root mean square error for train.csv = \" , rmse_train)\n",
    "\n",
    "\n",
    "#in test.csv\n",
    "rmse_test = rmse(test_avgs,const_avg_test)\n",
    "print(\"Root mean square error for test.csv = \" , rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity of train_matrix =  0.015778357559945336\n",
      "Sparsity of test_matrix =  0.006546644844517185\n"
     ]
    }
   ],
   "source": [
    "#1 d)\n",
    "\n",
    "\n",
    "#in train.csv\n",
    "rows_train = df_train['user_id'].unique()\n",
    "cols_train = df_train['book'].unique()\n",
    "data = df_train[['user_id', 'book', 'rating']]\n",
    "idict_train = dict(zip(cols_train, range(len(cols_train))))\n",
    "udict_train = dict(zip(rows_train, range(len(rows_train))))\n",
    "data.user_id = [ udict_train[i] for i in data.user_id ]\n",
    "data['book'] = [ idict_train[i] for i in data['book'] ]\n",
    "nmat_train = data.as_matrix()\n",
    "#print(nmat_train)\n",
    "naive_train = np.zeros((len(rows_train),len(cols_train)))\n",
    "for row in nmat_train:\n",
    "    naive_train[row[0],row[1]] = row[2]\n",
    "    \n",
    "print(\"Sparsity of train_matrix = \", np.count_nonzero(nmat_train==0)/np.prod(nmat_train.shape))\n",
    "\n",
    "\n",
    "#in test.csv\n",
    "rows_test = df_test['user_id'].unique()\n",
    "cols_test = df_test['book'].unique()\n",
    "data = df_test[['user_id', 'book', 'rating']]\n",
    "idict_test = dict(zip(cols_test, range(len(cols_test))))\n",
    "udict_test = dict(zip(rows_test, range(len(rows_test))))\n",
    "data.user_id = [ udict_test[i] for i in data.user_id ]\n",
    "data['book'] = [ idict_test[i] for i in data['book'] ]\n",
    "nmat_test = data.as_matrix()\n",
    "#print(nmat_test)\n",
    "naive_test = np.zeros((len(rows_test),len(cols_test)))\n",
    "for row in nmat_test:\n",
    "    naive_test[row[0],row[1]] = row[2]\n",
    "print(\"Sparsity of test_matrix = \", np.count_nonzero(nmat_test==0)/np.prod(nmat_test.shape))\n",
    "#print(udict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean square error for train.csv =  1.1444196071250665\n",
      "Root mean square error for test.csv =  1.0777148094967743\n"
     ]
    }
   ],
   "source": [
    "#1 e)\n",
    "def predict_naive(user, item):\n",
    "    \n",
    "    prediction = imean[item] + umean[user] - amean\n",
    "    return prediction\n",
    "\n",
    "# train/test_means = umean ; train/test_item_means = imean ; df_train/test_avg = amean\n",
    "\n",
    "def mean_fn(naive):\n",
    "    amean1 = np.mean(naive[naive!=0])\n",
    "    umean1 = sum(naive.T) / sum((naive!=0).T)\n",
    "    umean1 = umean1[~np.isnan(umean1)]\n",
    "    imean1 = sum(naive) / sum((naive!=0))\n",
    "    imean1 = imean1[~np.isnan(imean1)]\n",
    "    \n",
    "    return amean1,umean1,imean1\n",
    "\n",
    "\n",
    "#for train.csv\n",
    "\n",
    "#naive = np.zeros((len(rows_train),len(cols_train)))\n",
    "predictions =[]\n",
    "targets = []\n",
    "\n",
    "amean,umean,imean = mean_fn(naive_train)\n",
    "for row in nmat_train:\n",
    "    #naive[row[0], row[1]] = row[2]\n",
    "    user, item, actual = row[0], row[1], row[2]\n",
    "    predictions.append(predict_naive(int(user), int(item)))\n",
    "    targets.append(actual)\n",
    "\n",
    "\n",
    "\n",
    "rmse_train = rmse(targets,predictions)\n",
    "print(\"Root mean square error for train.csv = \" , rmse_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for test.csv\n",
    "#naive = np.zeros((len(rows_test),len(cols_test)))\n",
    "amean,umean,imean = mean_fn(naive_test)\n",
    "predictions =[]\n",
    "targets = []\n",
    "for row in nmat_test:\n",
    "    #naive[row[0], row[1]] = row[2]\n",
    "    user, item, actual = row[0], row[1], row[2]\n",
    "    predictions.append(predict_naive(int(user), int(item)))\n",
    "    targets.append(actual)\n",
    "\n",
    "    \n",
    "\n",
    "rmse_test = rmse(targets,predictions)\n",
    "print(\"Root mean square error for test.csv = \" , rmse_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 a)\n",
    "\n",
    "#operating on test.csv\n",
    "\n",
    "def cosine(vec1,vec2):\n",
    "    return np.dot(vec1,vec2)/(np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "def cos(mat, a, b):\n",
    "    if a == b:\n",
    "        return 1\n",
    "    aval = mat.T[a].nonzero()\n",
    "    bval = mat.T[b].nonzero()\n",
    "    corated = np.intersect1d(aval, bval)\n",
    "    if len(corated) == 0:\n",
    "        return 0\n",
    "    avec = np.take(mat.T[a], corated)\n",
    "    bvec = np.take(mat.T[b], corated)\n",
    "    val = 1 - cosine(avec, bvec)\n",
    "    if np.isnan(val):\n",
    "        return 0\n",
    "    return val\n",
    "\n",
    "def pr(mat, a, b, imean):\n",
    "    if a == b:\n",
    "        return 1\n",
    "    aval = mat.T[a].nonzero()\n",
    "    bval = mat.T[b].nonzero()\n",
    "    corated = np.intersect1d(aval, bval)\n",
    "    if len(corated) < 2:\n",
    "        return 0\n",
    "    avec = np.take(mat.T[a], corated)\n",
    "    bvec = np.take(mat.T[b], corated)\n",
    "    avec1 = avec - imean[a]\n",
    "    bvec1 = bvec - imean[b]\n",
    "    val = 1 - cosine(avec1, bvec1)\n",
    "    if np.isnan(val):\n",
    "        return 0\n",
    "    return val\n",
    "\n",
    "def itemsimilar(mat,option):\n",
    "    #rows = data.user_id.unique()\n",
    "    #cols = data['book'].unique()\n",
    "    #naive = np.zeros((len(rows),len(cols)))\n",
    "    amean ,umean , imean = mean_fn(mat)\n",
    "    \n",
    "    n = mat.shape[1]\n",
    "    sim_mat = np.zeros((n,n))\n",
    "    \n",
    "    if option=='pr':\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                sim_mat[i][j] = pr(mat, i, j, imean)\n",
    "        sim_mat = (sim_mat + 1)/2\n",
    "    elif option == 'cos':\n",
    "        #print(\"COS\")\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                sim_mat[i][j] = cos(mat, i, j)\n",
    "    else:\n",
    "        #print(\"Default\")\n",
    "        sim_mat = cosine_similarity(mat.T)\n",
    "    return sim_mat, amean, umean, imean\n",
    "    \n",
    "\n",
    "#cos_sim_5 = itemsimilar(nmat_test,'cos')\n",
    "#[item, nzero].argsort()[::-1][:k]\n",
    "#print(cos_sim_5)\n",
    " \n",
    "def user_sim_cos(user,k):\n",
    "    l =[]\n",
    "    for i in range(nmat_test.shape()[0]):\n",
    "        l.append(cos(nmat_test,user,i))\n",
    "    \n",
    "    l.remove(1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 b)\n",
    "\n",
    "def predict(user, item, mat, item_similarity, amean, umean, imean,k=5):\n",
    "    nzero = mat[user].nonzero()[0]\n",
    "    if len(nzero) == 0:\n",
    "        return amean\n",
    "    baseline = imean + umean[user] - amean\n",
    "    choice = nzero[item_similarity[item, nzero].argsort()[::-1][:k]]\n",
    "    \n",
    "    prediction = ((mat[user, choice] - baseline[choice]).dot(item_similarity[item,choice])/ sum(item_similarity[item, choice])) + baseline[item]\n",
    "    if np.isnan(prediction):\n",
    "        prediction = amean\n",
    "    if prediction > 10:\n",
    "        prediction = 10\n",
    "    if prediction < 1:\n",
    "        prediction = 1\n",
    "    return prediction\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error\n",
      "RMSE : 0.0543\n",
      "Test Error\n",
      "RMSE : 0.0060\n"
     ]
    }
   ],
   "source": [
    "#2 c)\n",
    "\n",
    "def get_results(train_data, test_data,option, k):\n",
    "    # train_data.rename(columns={'user_id':'book','book':'user_id', 'rating':'rating'}, inplace = True)\n",
    "    rows = train_data.user_id.unique()\n",
    "    cols = train_data['book'].unique()\n",
    "    train_data = train_data[['user_id', 'book', 'rating']]\n",
    "    idict = dict(zip(cols, range(len(cols))))\n",
    "    udict = dict(zip(rows, range(len(rows))))\n",
    "    train_data.user_id = [ udict[i] for i in train_data.user_id ]\n",
    "    train_data['book'] = [ idict[i] for i in train_data['book'] ]\n",
    "    mat = train_data.as_matrix()\n",
    "    full_mat = np.zeros((len(rows),len(cols)))\n",
    "    for row in mat:\n",
    "        full_mat[row[0], row[1]] = row[2]\n",
    "    item_similarity, amean, umean, imean = itemsimilar(full_mat, option)\n",
    "    preds=[]\n",
    "    real=[]\n",
    "    for i in mat:\n",
    "        preds.append(predict(i[0], i[1], full_mat, item_similarity, amean, umean, imean, k=5))\n",
    "        real.append(i[2])\n",
    "    err1 = mean_squared_error(preds,real)\n",
    "    print('Train Error')\n",
    "    print('RMSE : %.4f' % err1)\n",
    "\n",
    "    # test_data.rename(columns={'user_id':'book','book':'user_id', 'rating':'rating'}, inplace = True)\n",
    "    rows = test_data.user_id.unique()\n",
    "    cols = test_data['book'].unique()\n",
    "    test_data = test_data[['user_id', 'book', 'rating']]\n",
    "    idict = dict(zip(cols, range(len(cols))))\n",
    "    udict = dict(zip(rows, range(len(rows))))\n",
    "    test_data.user_id = [ udict[i] for i in test_data.user_id ]\n",
    "    test_data['book'] = [ idict[i] for i in test_data['book'] ]\n",
    "    mat = test_data.as_matrix()\n",
    "    full_mat = np.zeros((len(rows),len(cols)))\n",
    "    for row in mat:\n",
    "        full_mat[row[0], row[1]] = row[2]\n",
    "    item_similarity, amean, umean, imean = itemsimilar(full_mat, option)\n",
    "    preds=[]\n",
    "    real=[]\n",
    "    for i in mat:\n",
    "        preds.append(predict(i[0], i[1], full_mat, item_similarity, amean, umean, imean, k=5))\n",
    "        real.append(i[2])\n",
    "    err2 = mean_squared_error(preds,real)\n",
    "    print('Test Error')\n",
    "    print('RMSE : %.4f' % err2)\n",
    "    '''\n",
    "    rows = train_data['user_id'].unique()\n",
    "    cols = train_data['book'].unique()\n",
    "    train_data = train_data[['user_id', 'book', 'rating']]\n",
    "    idict = dict(zip(cols, range(len(cols))))\n",
    "    udict = dict(zip(rows, range(len(rows))))\n",
    "    train_data.user_id = [ udict[i] for i in train_data.user_id ]\n",
    "    train_data['book'] = [ idict[i] for i in train_data['book'] ]\n",
    "    mat = train_data.as_matrix()\n",
    "    full_mat = np.zeros((len(rows),len(cols)))\n",
    "    for row in train_data:\n",
    "        full_mat[row[0], row[1]] = row[2]\n",
    "        \n",
    "    item_similarity, amean, umean, imean = itemsimilar(full_mat, option)\n",
    "    preds = []\n",
    "    real =[]\n",
    "    \n",
    "    #predict(i[0], i[1], full_mat, item_similarity, amean, umean, imean, k=5)\n",
    "    \n",
    "    for row in train_data:\n",
    "        user, item, actual = row[0], row[1], row[2]\n",
    "        preds.append(predict(user, item,full_mat,item_similarity,amean,umean,imean,k=5))\n",
    "        real.append(actual)\n",
    "    \n",
    "    err1 = rmse(real,preds)\n",
    "    print('Train Error')\n",
    "    print('RMSE : %.4f' % err1)\n",
    "    \n",
    "    rows = test_data['user_id'].unique()\n",
    "    cols = test_data['book'].unique()\n",
    "    test_data = test_data[['user_id', 'book', 'rating']]\n",
    "    idict = dict(zip(cols, range(len(cols))))\n",
    "    udict = dict(zip(rows, range(len(rows))))\n",
    "    test_data.user_id = [ udict[i] for i in test_data.user_id ]\n",
    "    test_data['book'] = [ idict[i] for i in test_data['book'] ]\n",
    "    mat = test_data.as_matrix()\n",
    "    full_mat = np.zeros((len(rows),len(cols)))\n",
    "    \n",
    "    item_similarity, amean, umean, imean = itemsimilar(full_mat, option)\n",
    "    \n",
    "    real = []\n",
    "    preds = []\n",
    "    \n",
    "    for row in test_data:\n",
    "        user, item, actual = row[0], row[1], row[2]\n",
    "        preds.append(predict(user, item,full_mat,item_similarity,amean,umean,imean,k=5))\n",
    "        real.append(actual)\n",
    "\n",
    "    err2 = rmse(real,preds)\n",
    "    print('Test Error')\n",
    "    print('RMSE : %.4f' % err2)\n",
    "    '''\n",
    "\n",
    "#amean,umean,imean = mean_fn(naive_train)\n",
    "#rows = df_train['user_id'].unique()\n",
    "#cols = df_train['book'].unique()\n",
    "get_results(pd.read_csv(\"train.csv\"), pd.read_csv(\"test.csv\"), \"cos\", 5)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
